import { NextRequest, NextResponse } from 'next/server';
import { GoogleGenAI, Type, Schema } from "@google/genai";
import { Message } from '@/types';

// System instruction for the chat interaction
const CHAT_SYSTEM_INSTRUCTION = `
You are an expert Medical Triage Nurse AI, communicating in Simplified Chinese (ÁÆÄ‰Ωì‰∏≠Êñá).
Your goal is to interview the patient to understand their "Chief Complaint" (‰∏ªËØâ).

CRITICAL RULES:
1. ASK ONE QUESTION AT A TIME: Ask only ONE question per response. Do NOT return multiple questions.
2. ASK FEW QUESTIONS TOTAL: Plan to ask only 3-5 questions total throughout the conversation.
3. BE CONCISE: Questions must be short (under 20 words).
4. GENERATE OPTIONS: You MUST provide a list of 4-6 predefined short options (answers) in Chinese.
   - If inquiring about specific pain/location, use Single Choice (allowMultiple: false).
   - If inquiring about associated symptoms (e.g., "Do you also have...?"), use Multiple Choice (allowMultiple: true).
   - Always include "ÂÖ∂‰ªñ" (Other) or "Êó†" (None).

OUTPUT FORMAT (JSON):
{
  "question": "‰Ω†ÁöÑ‰∏Ä‰∏™ÈóÆÈ¢ò",
  "options": ["ÈÄâÈ°π1", "ÈÄâÈ°π2", "ÈÄâÈ°π3", "ÈÄâÈ°π4"],
  "allowMultiple": false
}

Tone: Professional, empathetic, efficient.
`;

// Schema for the chat response with options
const CHAT_RESPONSE_SCHEMA: Schema = {
  type: Type.OBJECT,
  properties: {
    question: { 
      type: Type.STRING, 
      description: "The follow-up question to the patient in Chinese." 
    },
    options: { 
      type: Type.ARRAY, 
      items: { type: Type.STRING },
      description: "A list of 4-6 short, likely answers in Chinese for the user to click."
    },
    allowMultiple: { 
      type: Type.BOOLEAN,
      description: "True if the user can select multiple options, False for single choice."
    }
  },
  required: ["question", "options", "allowMultiple"]
};

export async function POST(request: NextRequest) {
  console.log('üöÄ Chat API called');
  
  try {
    const { history, message } = await request.json();

    const apiKey = process.env.GEMINI_API_KEY;
    const baseUrl = process.env.GEMINI_BASE_URL || 'https://generativelanguage.googleapis.com';

    // ËØ¶ÁªÜÁöÑÁéØÂ¢ÉÊ£ÄÊü•
    console.log('üìã Environment:', {
      hasApiKey: !!apiKey,
      apiKeyLength: apiKey?.length || 0,
      baseUrl,
      isVercel: !!process.env.VERCEL,
      vercelEnv: process.env.VERCEL_ENV,
    });

    if (!apiKey) {
      console.error('‚ùå ERROR: GEMINI_API_KEY not found');
      return NextResponse.json(
        { error: 'API Key not configured. Check Vercel environment variables.' },
        { status: 500 }
      );
    }

    console.log('üîß Using direct HTTP API:', {
      baseUrl,
      apiKeyPrefix: apiKey.substring(0, 15) + '...',
    });

    // ÊûÑÂª∫Ê∂àÊÅØÔºàÊ∑ªÂä†Á≥ªÁªüÊåá‰ª§‰Ωú‰∏∫Á¨¨‰∏ÄÊù°Ê∂àÊÅØÔºâ
    const messages = [
      {
        role: 'user',
        parts: [{ text: CHAT_SYSTEM_INSTRUCTION + '\n\nYou MUST respond in valid JSON format.' }]
      },
      ...history.map((msg: Message) => ({
        role: msg.role === 'model' ? 'model' : 'user',
        parts: [{ text: msg.text }]
      })),
      {
        role: 'user',
        parts: [{ text: message }]
      }
    ];

    // ‰ΩøÁî®Áõ¥Êé• HTTP ËØ∑Ê±ÇË∞ÉÁî® API
    const apiUrl = `${baseUrl}/v1beta/models/gemini-2.5-flash:generateContent?key=${apiKey}`;
    
    console.log('üì§ Sending request...');
    const response = await fetch(apiUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        contents: messages,
        generationConfig: {
          temperature: 0.5,
          topK: 40,
          topP: 0.95,
          maxOutputTokens: 1024,
          responseMimeType: 'application/json'
        }
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('‚ùå API Error Response:', {
        status: response.status,
        statusText: response.statusText,
        error: errorText.substring(0, 500)
      });
      throw new Error(`API Error: ${response.status} - ${errorText.substring(0, 100)}`);
    }

    const data = await response.json();
    console.log('‚úÖ Received response');

    // Ëß£ÊûêÂìçÂ∫î
    const text = data.candidates?.[0]?.content?.parts?.[0]?.text;
    if (!text) {
      throw new Error('No text in response');
    }

    // ËÆ∞ÂΩïÂÆåÊï¥ÁöÑÂéüÂßãÂìçÂ∫îÔºàÁî®‰∫éË∞ÉËØïÔºâ
    console.log('üìÑ Raw response text (length:', text.length, ')');
    console.log('First 500 chars:', text.substring(0, 500));
    if (text.length > 500) {
      console.log('Last 200 chars:', text.substring(text.length - 200));
    }

    // Ê∏ÖÁêÜÂíåËß£Êûê JSON
    let parsed;
    try {
      // Â∞ùËØïÊ∏ÖÁêÜ JSON Â≠óÁ¨¶‰∏≤
      let cleanedText = text.trim();
      
      // Â¶ÇÊûúÊñáÊú¨Ë¢´ markdown ‰ª£Á†ÅÂùóÂåÖË£πÔºåÁßªÈô§ÂÆÉ‰ª¨
      if (cleanedText.startsWith('```json')) {
        cleanedText = cleanedText.replace(/^```json\s*/i, '').replace(/\s*```$/, '');
      } else if (cleanedText.startsWith('```')) {
        cleanedText = cleanedText.replace(/^```\s*/, '').replace(/\s*```$/, '');
      }
      
      // ‰∏çË¶ÅÊõøÊç¢Êç¢Ë°åÁ¨¶ÔºåÂõ†‰∏∫ JSON Â≠óÁ¨¶‰∏≤ÂÄºÂÜÖÈÉ®ÂèØËÉΩÂåÖÂê´Êç¢Ë°åÁ¨¶
      // Âè™ÁßªÈô§ÁúüÊ≠£ÁöÑÊéßÂà∂Â≠óÁ¨¶Ôºà‰øùÁïô \n, \r, \tÔºâ
      cleanedText = cleanedText
        .replace(/[\u0000-\u0008\u000B-\u000C\u000E-\u001F\u007F-\u009F]/g, '')
        .trim();
      
      // Á°Æ‰øùÂ≠óÁ¨¶‰∏≤ÂÆåÊï¥Èó≠Âêà
      const openBraces = (cleanedText.match(/{/g) || []).length;
      const closeBraces = (cleanedText.match(/}/g) || []).length;
      const openBrackets = (cleanedText.match(/\[/g) || []).length;
      const closeBrackets = (cleanedText.match(/\]/g) || []).length;
      
      if (openBraces > closeBraces) {
        console.log('üîß Adding missing closing braces:', openBraces - closeBraces);
        cleanedText += '}'.repeat(openBraces - closeBraces);
      }
      if (openBrackets > closeBrackets) {
        console.log('üîß Adding missing closing brackets:', openBrackets - closeBrackets);
        cleanedText += ']'.repeat(openBrackets - closeBrackets);
      }
      
      console.log('üßπ Cleaned text (first 500):', cleanedText.substring(0, 500));
      
      parsed = JSON.parse(cleanedText);
      console.log('üìä Parsed response structure:', Object.keys(parsed));
      console.log('üìä Full parsed:', JSON.stringify(parsed, null, 2).substring(0, 1000));
    } catch (parseError) {
      console.error('‚ùå JSON Parse Error:', parseError);
      console.error('Failed text (first 800 chars):', text.substring(0, 800));
      console.error('Failed text (last 200 chars):', text.substring(text.length - 200));
      throw new Error(`Invalid JSON response from AI: ${parseError instanceof Error ? parseError.message : 'Unknown error'}`);
    }
    
    // Â§ÑÁêÜ‰∏çÂêåÁöÑÂìçÂ∫îÊ†ºÂºè
    let questionText = '';
    let options: string[] = [];
    let allowMultiple = false;
    
    // Ê£ÄÊü•ÊòØÂê¶ÊòØ questions Êï∞ÁªÑÊ†ºÂºèÔºàËøîÂõû‰∫ÜÂ§ö‰∏™ÈóÆÈ¢òÔºâ
    if (parsed.questions && Array.isArray(parsed.questions) && parsed.questions.length > 0) {
      console.warn('‚ö†Ô∏è Received questions array format, using first question');
      const firstQuestion = parsed.questions[0];
      questionText = firstQuestion.question || 'ËØ∑ÊèèËø∞ÊÇ®ÁöÑÁóáÁä∂';
      options = firstQuestion.options || [];
      allowMultiple = firstQuestion.type === 'Multiple Choice';
      console.log(`üìù Extracted first question from ${parsed.questions.length} questions`);
    }
    // Ê£ÄÊü•ÊòØÂê¶ÊòØÈîôËØØÁöÑ dialogue Ê†ºÂºè
    else if (parsed.dialogue && Array.isArray(parsed.dialogue)) {
      console.warn('‚ö†Ô∏è Received dialogue format instead of expected format');
      // Â∞ùËØï‰ªé dialogue ‰∏≠ÊèêÂèñÈóÆÈ¢ò
      const aiMessage = parsed.dialogue.find((d: any) => d.speaker === 'AI' || d.role === 'assistant');
      questionText = aiMessage?.text || 'ËØ∑ÊèèËø∞ÊÇ®ÁöÑÁóáÁä∂';
      // ‰ΩøÁî®ÈªòËÆ§ÈÄâÈ°π
      options = ['ÁªßÁª≠', 'ÈáçÊñ∞ÂºÄÂßã'];
      allowMultiple = false;
    } 
    // Ê≠£Á°ÆÁöÑÂçï‰∏™ÈóÆÈ¢òÊ†ºÂºè
    else if (parsed.question) {
      questionText = parsed.question;
      options = parsed.options || [];
      
      // Â§ÑÁêÜ optionsÔºöÂ¶ÇÊûúÊòØÂØπË±°Êï∞ÁªÑÔºåÊèêÂèñÊñáÊú¨Â≠óÊÆµ
      if (options.length > 0 && typeof options[0] === 'object') {
        options = options.map((opt: any) => opt.text || opt.value || String(opt));
      }
      
      allowMultiple = parsed.allowMultiple || parsed.question_type === 'multiple_choice' || false;
    } 
    // Êú™Áü•Ê†ºÂºè
    else {
      console.error('‚ùå Unknown response format:', Object.keys(parsed));
      console.error('Full parsed object:', JSON.stringify(parsed, null, 2));
      throw new Error('Unexpected response format from AI');
    }
    
    console.log('‚úÖ Final response:', { questionText, optionsCount: options.length, allowMultiple });
    
    return NextResponse.json({
      text: questionText,
      options: options,
      allowMultiple: allowMultiple
    });

  } catch (error) {
    console.error("‚ùå Error in chat:", error);
    
    if (error instanceof Error) {
      console.error('Error details:', {
        name: error.name,
        message: error.message,
        stack: error.stack?.split('\n').slice(0, 3).join('\n')
      });
    }
    
    const errorMessage = error instanceof Error ? error.message : String(error);
    return NextResponse.json(
      { 
        error: `Á≥ªÁªüÈîôËØØÔºö${errorMessage}`,
        hint: 'Check Vercel function logs for details'
      },
      { status: 500 }
    );
  }
}
